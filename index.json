[{"authors":["admin"],"categories":null,"content":"Hi! Welcome to my webpage.\nI am Abhishek Nayak, a Ph.D. candidate in the Department of Mechanical Engineering at Texas A\u0026amp;M University, where I work as a Graduate Research Assistant with the Autonomous Systems Laboratory. My research explores \u0026lsquo;Planning and Vision-based methods for Autonomous Vehicles.\u0026rsquo; I am an advocate of safe transportation and am currently working with the Texas A\u0026amp;M Transportation Institute on SAFE-D projects that aim at improving standards of road safety. Previously, for my Master\u0026rsquo;s research, I worked on developing vision-based safe response protocols for autonomous vehicles towards emergency response vehicles.\nMy research interests broadly include - 1) Perception Models for Mobile Robots, 2) Heuristics and Optimization for Task Allocation and Motion Planning, and 3) Learning-based methods for constrained Motion Planning. During my time at Texas A\u0026amp;M, I was able to explore these topics (and beyond) in-depth and gain practical knowledge by applying my research for field-experiments on an autonomous Lincoln MKZ vehicle (a teaser). I am also an experienced industry professional and have worked in the automotive industry for three years as an R\u0026amp;D Engineer in the powertrains section of TVS Motor Company, India.\nBesides academics, I enjoy playing tennis, running, cooking, and traveling.\n","date":1549324800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://nykabhishek.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Hi! Welcome to my webpage.\nI am Abhishek Nayak, a Ph.D. candidate in the Department of Mechanical Engineering at Texas A\u0026amp;M University, where I work as a Graduate Research Assistant with the Autonomous Systems Laboratory.","tags":null,"title":"Abhishek Nayak","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://nykabhishek.github.io/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://nykabhishek.github.io/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://nykabhishek.github.io/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. --   ","date":1634304600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634304600,"objectID":"e041b596021df9443504b4b81635d526","permalink":"https://nykabhishek.github.io/talk/21_10_15_safed_webinar/","publishdate":"2021-10-15T13:30:00Z","relpermalink":"/talk/21_10_15_safed_webinar/","section":"talk","summary":"SAFE-D Webinar on Reference Machine Vision for ADAS Functions","tags":[],"title":"Webinar - Reference Machine Vision for ADAS Functions","type":"talk"},{"authors":null,"categories":null,"content":"Location: Autonomous Systems Laboratory (https://autonomy.engr.tamu.edu/), Texas A\u0026amp;M University - College Station, TX\n ROSBots by Husarion  --     ","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"75901ef2abbccdecf0cadae970d6180f","permalink":"https://nykabhishek.github.io/project/multislam/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/project/multislam/","section":"project","summary":"In this project, I implemented multi-agent SLAM to obtain occupancy grid maps from point-cloud data via autonomous frontier exploration using ROSBots 2.0 by Husarion. I tinkered around to establish navigation capabilities on this robot and used algorithms like Dijkstra, A*, D* lite, RRT, and Probabilistic Roadmap (PRM) planners for indoor navigation. Further, I used these robots as a platform for demonstrating proof-of-concept prototypes of multi-agent path planning methods developed as part of my Ph.D. thesis \"Planning and Vision-based tools for Autonomous Vehicles.\"","tags":["Motion Planning","Algorithms","Heuristics"],"title":"Multi-Agent SLAM and navigation using ROSBot","type":"project"},{"authors":null,"categories":null,"content":"Location: Autonomous Systems Laboratory (https://autonomy.engr.tamu.edu/), Texas A\u0026amp;M University - College Station, TX\n --  Collaborators: Satyanarayana G Manyam (https://scholar.google.com/citations?user=biUXytYAAAAJ\u0026hl=en\u0026oi=ao) ","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"cd4b134e82b7ffcc5b35d732aba70f9d","permalink":"https://nykabhishek.github.io/project/obstacle/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/project/obstacle/","section":"project","summary":"In this work, I worked on developing optimized algorithms to establish bounds on paths of curvature-constrained vehicles in the presence of obstacles.","tags":["Motion Planning","Algorithms","Heuristics"],"title":"Robotic motion planning algorithms in presence of obstacles","type":"project"},{"authors":["S. K. K. Hari","A. Nayak","S. Rathinam"],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"66c6af6d2c0c85cdcfd590f284bfc2c7","permalink":"https://nykabhishek.github.io/publication/8977310/","publishdate":"2020-03-22T05:35:56.031343Z","relpermalink":"/publication/8977310/","section":"publication","summary":"This article presents an approximation algorithm for a Task Allocation, Sequencing and Scheduling Problem (TASSP) involving a team of human operators and robots. The robots have to travel to a given set of targets and collaboratively work on the tasks at the targets with the human operators. The problem aims to find a sequence of targets for each robot to visit and schedule the tasks at the targets with the human operators such that each target is visited exactly once by some robot, the scheduling constraints are satisfied and the maximum mission time of any robot is minimum. This problem is a generalization of the single Traveling Salesman Problem and is NP-Hard. Given $k$ robots and $m$ human operators, an algorithm is developed for solving the TASSP with an approximation ratio equal to $\u000crac{5}{2}-\u000cracfrac{1}{k}$ when $m≥ k$ and equal to $\u000crac{7]}{2}-\u000crac{1}{k}$ otherwise. Computational results are also presented to corroborate the performance of the proposed algorithm.","tags":null,"title":"An Approximation Algorithm for a Task Allocation, Sequencing and Scheduling Problem Involving a Human-Robot Team","type":"publication"},{"authors":null,"categories":null,"content":"Location: Autonomous Systems Laboratory (https://autonomy.engr.tamu.edu/), Texas A\u0026amp;M University - College Station, TX\n  Work in progress... Watch this space for more updates   Arduino microcontroller based drive-by-wire setup.      -- ","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"50d211189cd4407f4ae88cdb98361e5e","permalink":"https://nykabhishek.github.io/project/vns_dubins/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/vns_dubins/","section":"project","summary":"As a part of this work, I developed graph search heuristics, formulated mixed-Integer programs (MIP), trained graph CNNs, and reinforcement learning (RL) models to solve min-max task assignment problems for a fleet of non-holonomic vehicles curvature-constrained multi-vehicle routing problems. A comparative study was performed to evaluate performance on different metaheuristics, primarily the Variable Neighborhood Search (VNS). The reinforcement learning (RL) models and graph CNNs are implemented and trained using PyTorch. The MIP formulations were solved using CPLEX and gurobi solvers on high-performance computing servers.","tags":["Motion Planning","Heuristics","Algorithms"],"title":"Heuristics and Reinforcement learning models for curvature constrained vehicle routing problems","type":"project"},{"authors":["Abhishek Nayak","Sivakumar Rathinam","Adam Pike","Swaminathan Gopalswamy"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"b45cc32477596c7e16e2c79b17ed5cdd","permalink":"https://nykabhishek.github.io/publication/nayak-2020-reference/","publishdate":"2020-03-22T05:35:56.030763Z","relpermalink":"/publication/nayak-2020-reference/","section":"publication","summary":"LDW and LKA systems have the potential to prevent or mitigate 483,000 crashes in the United States every year which includes 87,000 nonfatal injury crashes and 10,345 fatal crashes. Studies have shown that fatalities due to unintentional roadway departures can be significantly reduced if Lane Departure Warning (LDW) and Lane Keep Assist (LKA) systems are used effectively. While LDW and LKA technologies are available, there has been low customer acceptance and penetration of these technologies. These deficiencies can be traced to the inability of many of the perception systems to consistently recognize lane markings and localize the vehicle with respect to the lane marking in a real-world environment of variable markings, changing weather and occlusions. These challenges translate to (i) inconsistent lane detection; (ii) misidentification of lane markings; and (iii) the inability of the systems to locate lane markings in some conditions. Currently, there is no available standard or benchmark to evaluate the quality of either the lane markings or the perception algorithms. This project seeks to establish a reference test system that could be used by transportation agencies to evaluate the quality of their markings to support ADAS functions that rely on pavement markings. The test system can also be used by system designers as a benchmark for their proprietary systems. The reference test system is comprised of a set of test scenarios, defined by roadway and environmental features, as well as pavement marking presence and luminance variables. To support the development of the system, an extensive video dataset was collected at different times of day and weather conditions on various roads in Central Texas. The videos were evaluated on different state-of-the-art lane detection algorithms and their performance was ranked based on a set of metrics specifically developed for evaluating the effectiveness of lane estimation system. A systems approach is presented by correlating the algorithm performance data to the type, marking color, marking material, and the retroreflectivity of pavement markings. Using the results obtained, a reference Lane Detection (LD) system is proposed to benchmark and rank new perception algorithms, sensors, and lane markings that constitute a reference lane system.","tags":null,"title":"Reference Test System for Machine Vision Used for ADAS Functions","type":"publication"},{"authors":[],"categories":null,"content":"   Event Flyer   ","date":1570728600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570728600,"objectID":"8747ec2f15f17b1ee0ba241f608773be","permalink":"https://nykabhishek.github.io/talk/19_10_10_safed_utc/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_10_10_safed_utc/","section":"talk","summary":"A brief on my activites as a TTI Researcher at the Safe-D UTC Graduate Student Leadership Development Seminars.","tags":[],"title":"Invited talk - Referance Machine Vision for ADAS Functions","type":"talk"},{"authors":[],"categories":null,"content":"   Poster    Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1570728600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570728600,"objectID":"610b755e8f4f97d3663d10075f93529a","permalink":"https://nykabhishek.github.io/talk/19_07_16_avs_rmv/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_07_16_avs_rmv/","section":"talk","summary":"Poster presentation at the Automated Vehicles Symposium 2019, Orlando FL","tags":[],"title":"Poster presentation - Reference Machine Vision for ADAS","type":"talk"},{"authors":["D. Ravipati","K. Chour","A. Nayak","T. Marr","S. Dey","A. Gautam","S. Rathinam","G. Swaminathan"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"044cc08fca99dc63b76ea03aeaee36e6","permalink":"https://nykabhishek.github.io/publication/8916896/","publishdate":"2020-03-22T05:35:56.032097Z","relpermalink":"/publication/8916896/","section":"publication","summary":"Infrastructure Enabled Autonomy (IEA) is a new paradigm in autonomous vehicles research that aims at distributed intelligence architecture by transferring the core functionalities of sensing and localization to infrastructure. This paradigm is also promising in designing scalable systems that enable autonomous car platooning on highways. This paper gives a detailed description about the experimental realization of IEA and techniques devised to localize a vehicle in such a setup. A reliable camera calibration technique for such an experimental setup is discussed, followed by a technique to transform 2D image coordinates to 3D world coordinates. In this research, localization information is received from on-board vehicle sensors like GPS/IMU, and (2) localized vehicle position data derived from deep learning, and 2D to 3D coordinate transformations on the real-time camera feeds and (3) lane detection data from infrastructure cameras. This data is fused together utilizing an Extended Kalman Filter (EKF) to obtain reliable estimates of the position of the vehicle at 50 Hz. This position information is then used to control the vehicle with an objective of following a prescribed path. Extensive simulation and experimental results are also presented to corroborate the performance of the proposed approach.","tags":null,"title":"Vision Based Localization for Infrastructure Enabled Autonomy","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://nykabhishek.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1556645400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556645400,"objectID":"a58c76a674386df3bc6e6239a9aba26c","permalink":"https://nykabhishek.github.io/talk/19_04_30_tti_rmv/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_04_30_tti_rmv/","section":"talk","summary":"Poster presentation at the 4th Annual Texas A\u0026M Transportation Technology Conference, College Station TX.","tags":[],"title":"Poster presentation - Reference Machine Vision for ADAS","type":"talk"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1556645400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556645400,"objectID":"72f5d24a263d97a954e572d812d9669d","permalink":"https://nykabhishek.github.io/talk/19_04_30_tti_ravev/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_04_30_tti_ravev/","section":"talk","summary":"Poster presentation at the 4th Annual Texas A\u0026M Transportation Technology Conference, College Station TX.","tags":[],"title":"Poster presentation - Response of Autonomous Vehicles to Emergency Vehicles","type":"talk"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1556038800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556038800,"objectID":"89ffe91c406020da9d794524e7bc8ace","permalink":"https://nykabhishek.github.io/talk/19_04_23_cscrs/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_04_23_cscrs/","section":"talk","summary":"Poster presentation at the 2019 CSCRS Safe Systems Summit, Durham NC.","tags":[],"title":"Poster presentation - Response of Autonomous Vehicles to Emergency Vehicles","type":"talk"},{"authors":["Abhishek Nayak"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://nykabhishek.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://nykabhishek.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":" Location: Texas A\u0026M Transportation Institute (TTI) - College Station, TX  Videos:        Abstract: Studies have shown that fatalities due to unintentional roadway departures can be significantly reduced if Lane Departure Warning (LDW) and Lane Keep Assist (LKA) systems are used effectively. However, these systems are not yet popular because the systems are not robust due, in part to the lack of suitable standards for pavement markings that enable reliable functionality of the sensor system. The objective of this project is to develop a reference Lane Detection (LD) system that will provide a benchmark for evaluating different lane markings, sensors, and perception algorithms. The goal of the project is to create a system that will validate the effectiveness of lane markings as well as the vision algorithms through a systematic development of LD metrics, and testing procedures for LD algorithms.  Follow this link to view the project on Safe-D Website.  This is Safe-D UTC sponsored project. (https://rip.trb.org/view/1599232)  Referances: Nayak, A., Pike, A., \u0026 Rathinam, S.(2022). Effect of pavement markings on machine vision used in ADAS functions (No. 2022-01-0154). SAE Technical Paper. Nayak, A., Pike, A., Rathinam, S., \u0026 Gopalswamy, S. (2020). Reference test system for machine vision used for ADAS functions (No. 2020-01-0096). SAE Technical Paper.  ","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"0c279eab384537c8e85b76b0d4ae2562","permalink":"https://nykabhishek.github.io/project/rmv/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/project/rmv/","section":"project","summary":"The objective of this project was to develop a reference system for lane detection (LD) that will provide a benchmark for evaluating different lane markings, sensors, and perception algorithms. I generated an extensive lane detection (LD) dataset by driving on various roads in Central Texas with changing weather conditions, time of day, pavement marking quality, and pavement materials. Further, I studied the relationship between lane marking quality and LD algorithm performance used in ADAS using statistical methods to propose a reference test system for state agencies and OEMs to benchmark lane marking quality and its effect on LD performance.","tags":["Deep Learning","Computer Vision"],"title":"Reference Machine Vision for ADAS functions","type":"project"},{"authors":["Abhishek Nayak","Swaminathan Gopalswamy","Sivakumar Rathinam"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d7a7731693b1f78e21b6610202cdb0ce","permalink":"https://nykabhishek.github.io/publication/nayak-2019-vision/","publishdate":"2020-03-22T05:35:56.03307Z","relpermalink":"/publication/nayak-2019-vision/","section":"publication","summary":"This paper discusses different computer vision techniques investigated by the authors for identifying Emergency Vehicles (EV). Two independent EV identification frameworks were investigated: (1) A one-stage framework where an object detection algorithm is trained on a custom dataset to detect EVs, (2) A two-stage framework where an object classification algorithm is implemented in series with an object detection pipeline to classify vehicles into EVs and non-EVs. A comparative study is conducted for different multi-spectral feature vectors of the image, against several classification models implemented in framework 2. Additionally, a user-defined feature vector is defined and its performance is compared against the other feature vectors. Classification outputs from each of the frameworks are compared to the ground truth, and results are quantitatively listed to conclude upon the ideal decision rule. As maintaining the speed of data output is the priority throughout our development, a computationally inexpensive object tracking algorithm is selected to accurately track EV between image frames. This vision-based EV detection scheme fused with data from other sensors on our autonomous vehicle shall be used to establish a sensor-fusion based EV detection and response framework in future work.","tags":null,"title":"Vision-Based Techniques for Identifying Emergency Vehicles","type":"publication"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1525800600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525800600,"objectID":"913ccfbb8aa51051098ffdebd7c73e8d","permalink":"https://nykabhishek.github.io/talk/18_05_18_tti_ravev/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/18_05_18_tti_ravev/","section":"talk","summary":"Poster presentation at the 3rd Annual Texas A\u0026M Transportation Technology Conference, College Station TX.","tags":[],"title":"Poster presentation - Response of Autonomous Vehicles to Emergency Vehicles","type":"talk"},{"authors":null,"categories":null,"content":"Location: Texas A\u0026M Transportation Institute (TTI) - College Station, TX --  Videos:    Emergency Vehicle (EV) detection: This video shows the emergency vehicles being detected by the trained YOLO-v3 object detector.    RAVEV - Hidden line of sight: This video shows the response by an autonomous vehicle when being followed by an EV with an obscured line of sight. This video was collected at RELLIS campus facility of Texas A\u0026M University.     RAVEV - Clear line of sight: This video shows the response by an autonomous vehicle when being followed by an EV with a clear line of sight. This video was collected at RELLIS campus facility of Texas A\u0026M University.     High-speed lane change: This video shows in action the high speed vehicle controller developed as a part of the RAVEV project. This video was collected at RELLIS campus facility of Texas A\u0026M University.  Visit Project Website here  Abstract: The objective of this project is to explore an ideal response action of an autonomous vehicle towards response vehicles in emergency scenarios using vision, sound and other sensors. I developed vision-based algorithms to reliably detect and track emergency vehicles from a video feed using image processing, machine learning, deep neural networks and other computer vison techniques.  This was a Safe-D UTC sponsored project (https://rip.trb.org/view/1500797).  Follow this link to view the Safe-D project website.  The final SAFE-D report can be viewed here.  References:  Nayak, A., Gopalswamy, S., \u0026 Rathinam, S. (2019). Vision-Based Techniques for Identifying Emergency Vehicles (No. 2019-01-0889). SAE Technical Paper. Nayak, A., Rathinam, S., \u0026 Gopalswamy, S. (2020). Response of Autonomous Vehicles to Emergency Response Vehicles (RAVEV) (No. 03-051).  ","date":1517011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517011200,"objectID":"8d7ffc4e72bf2066f3908f9c6ef1e952","permalink":"https://nykabhishek.github.io/project/ravev/","publishdate":"2018-01-27T00:00:00Z","relpermalink":"/project/ravev/","section":"project","summary":"The objective of this project was to develop response protocols for autonomous vehicles to safely respond to different classes of emergency vehicles using fused data from sound, vision, and other onboard sensors. As a part of this project, I generated an Emergency Vehicle (EV) image dataset and trained computer vision models to identify and localize EVs in crowded environments. I trained ML models using decision trees, nearest neighbors, boosting, and SVM on different feature vectors to perform EV classification and implemented Spatio-temporal multi-object tracking algorithms to track EVs in video sequences. Finally, we formulated two distinct frameworks for the response protocol of an autonomous vehicle in emergency scenarios.","tags":["Autonomous Vehicles","Computer Vision","Machine Learning","Deep Learning","Sensor Fusion"],"title":"Response of Autonomous Vehicles to Emergency Response Vehicles (RAVEV)","type":"project"},{"authors":["Abhishek Nayak","Kenny Chour","Tyler Marr","Deepika Ravipati","Sheelabhadra Dey","Alvika Gautam","Swaminathan Gopalswamy","Sivakumar Rathinam"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"9ad05b55efcac26f5c96ea0d14922bd4","permalink":"https://nykabhishek.github.io/publication/nayak-2018-distributed/","publishdate":"2020-03-22T05:35:56.029689Z","relpermalink":"/publication/nayak-2018-distributed/","section":"publication","summary":"Infrastructure Enabled Autonomy (IEA) is a new paradigm that employs a distributed intelligence architecture for connected autonomous vehicles by offloading core functionalities to the infrastructure. In this paper, we develop a simulation framework that can be used to study the concept. A key challenge for such a simulation is the rapid increase in the scale of the computations with the size of the infrastructure to be considered. Our simulation framework is designed to be distributed and scales proportionally with the infrastructure. By integrally using both the hardware controllers and communication devices as part of the simulation framework, we achieve an optimal balance between modeling of the dynamics and sensors, and reusing real hardware for simulation of proprietary or complex communication methods. Multiple cameras on the infrastructure are simulated. The simulation of the camera image processing is done in distributed hardware and the resultant position information is transmitted wirelessly to the computer simulating the autonomous vehicle. We demonstrate closed loop control of a single vehicle following given waypoints using information from multiple cameras located on Road-Side-Units.","tags":null,"title":"A Distributed Hybrid Hardware-in-the-loop Simulation Framework for Infrastructure Enabled Autonomy","type":"publication"},{"authors":null,"categories":null,"content":" Location: The Rellis campus, Texas A\u0026M University - College Station, TX Collaborators: CAST Program  Videos:            Abstract: IEA is a new paradigm in Autonomous Vehicle technology that looks at offloading the core computational capabilities of awareness generation and path planning from the vehicle out onto Smart Roadside Units equipped with various sensors. Through this distributed setup IEA provides a solution of shared liabilities by transferring the primary responsibility of localization from vehicle to infrastructure which in-turn enables of greater situational awareness of the area under the purview of IEA. IEA architecture is deployed on specific sections of roads or special traffic corridors by installing Road-Side Units (RSU) on either side of the road. These RSUs are fitted with multi-sensor smart packs (MSSP) containing sensors required for localizing vehicles. These MSSPs monitor the vehicles in the section of the roads under the purview of IEA and aid in generating the situational awareness which can be transmitted to the vehicles subscribing to this information. MSSP includes several sensors that carry-out specific individual tasks and as a whole aid in generating the localization information. For example, cameras installed on the RSUs as a part of the MSSP are used to monitor traffic by identifying and locating all the objects of interest in the traffic corridor. MSSPs are installed with special SmartConnect devices, whose function is to establish wireless connectivity between MSSPs and the vehicles subscribing to its information and thus enabling transmission of information necessary for its localization. The SmartConnect devices are communication medium agnostic and modular so that they can be easily substituted by newer technologies.  Referances: Nayak, A., Chour, K., Marr, T., Ravipati, D., Dey, S., Gautam, A., ... \u0026 Rathinam, S. (2018). A distributed hybrid hardware-in-the-loop simulation framework for infrastructure enabled autonomy. arXiv preprint arXiv:1802.01787. Ravipati, D., Chour, K., Nayak, A., Marr, T., Dey, S., Gautam, A., ... \u0026 Swaminathan, G. (2019, October). Vision Based Localization for Infrastructure Enabled Autonomy. In 2019 IEEE Intelligent Transportation Systems Conference (ITSC) (pp. 1638-1643). IEEE. Gopalswamy, S., \u0026 Rathinam, S. (2018, June). Infrastructure enabled autonomy: A distributed intelligence architecture for autonomous vehicles. In 2018 IEEE Intelligent Vehicles Symposium (IV) (pp. 986-992). IEEE.  ","date":1503792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503792000,"objectID":"de6fb5f0a909f7f6b2f76f2caae52db3","permalink":"https://nykabhishek.github.io/project/iea/","publishdate":"2017-08-27T00:00:00Z","relpermalink":"/project/iea/","section":"project","summary":"The objective of this project was to develop a distributed intelligence architecture for Connected Autonomous Vehicles (CAV) by offloading core computational functionalities to the infrastructure. I set up the Vehicle-to-Infrastructure (V2I) and Infrastructure-to-Infrastructure (I2I) communication network using DSRC and built software stacks on smart infrastructures for object detection, tracking, semantic segmentation, and localization. Further, I calibrated the cameras and sensor systems using OpenCV and developed SLAM capabilities for RSUs by fusing IMU, camera, GPS/RTK, and odometry data using estimation filters (like Monte-Carlo and Extended Kalman Filters (EKF)) for autonomous navigation of a Lincoln MKZ vehicle.","tags":["Autonomous Vehicles","Computer Vision","Deep Learning","Sensor Fusion"],"title":"Infrastructure Enabled Autonomy (IEA)","type":"project"},{"authors":null,"categories":null,"content":"Location: CAST Program (https://cast.tamu.edu/), Texas A\u0026amp;M University - College Station, TX\n  Arduino microcontroller based drive-by-wire setup.       Collaborators: Kenny Chour, PhD Student - Texas A\u0026M University ","date":1503360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503360000,"objectID":"f756b65fe8b4cad2715c77f4d1d5b680","permalink":"https://nykabhishek.github.io/project/focus/","publishdate":"2017-08-22T00:00:00Z","relpermalink":"/project/focus/","section":"project","summary":"I worked in a team of 3 to develop prototypes of a low-cost drive-by-wire system to control a Ford Focus vehicle via sensor emulation using Arduino Mega.","tags":["Autonomous Vehicles","Sensor Fusion"],"title":"Low-cost drive-by-wire system for Ford Focus","type":"project"},{"authors":["Abhishek Nayak"],"categories":["Demo"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\n Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n 👉 Get Started 📚 View the documentation 💬 Ask a question on the forum 👥 Chat with the community 🐦 Twitter: @source_themes @GeorgeCushen #MadeWithAcademic 💡 Request a feature or report a bug ⬆️ Updating? View the Update Guide and Release Notes ❤ Support development of Academic:  ☕️ Donate a coffee 💵 Become a backer on Patreon 🖼️ Decorate your laptop or journal with an Academic sticker 👕 Wear the T-shirt 👩‍💻 Contribute      Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\n Choose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem   Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site  Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n  one-click install using your web browser (recommended)  install on your computer using Git with the Command Prompt/Terminal app  install on your computer by downloading the ZIP files  install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating  View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://nykabhishek.github.io/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Abhishek Nayak","HS Ashwin","SM Murigendrappa"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"93b1f7b81488004101dc0c99b2559d67","permalink":"https://nykabhishek.github.io/publication/nayak-2016-stability/","publishdate":"2020-03-22T05:35:56.033939Z","relpermalink":"/publication/nayak-2016-stability/","section":"publication","summary":"During cornering of a two wheeler under dynamic conditions when the vehicle is steered to the left or right, the axis of the wheels and other rotating parts undergoes precession along with spinning which produces a gyroscopic couple. Due to the action of these moments on the vehicles along with the centrifugal forces and gravity acting on it, the vehicle may either skid or overturn depending on the angle of tilt, velocity of the motorcycle, radius of the curve \u0026 mass of the vehicle. The main objective of this work is to ensure the safe negotiation of the turn and to prevent accidents by establishing a harmonious relationship between the effecting parameters. A device was developed to act as a feedback control system; taking the inputs from a IMU sensor, predict the equilibrium conditions and thereby control the dynamic parameters of the 2 wheeler in order to enable it negotiate the curve safely.","tags":null,"title":"Stability Enhancement Of a Powered Two Wheeler Vehicle Under Curve Negotiation","type":"publication"}]