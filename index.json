[{"authors":["admin"],"categories":null,"content":"Hi! Welcome to my webpage.\nIâ€™m Abhishek Nayak, a Ph.D. candidate in the Department of Mechanical Engineering at Texas A\u0026amp;M University, College Station. My research interests include perception and motion planning for Robots. I am passionate about safe transportation and am currently working with the Texas A\u0026amp;M Transportation Institute on SAFE-D projects that aim at improving road safety standards.\nI have been part of the Autonomous Systems Laboratory at Texas A\u0026amp;M University, working with Dr. Sivakumar Rathinam since Fall 2017. I have extensive hands-on experience implementing robotic perception, computer vision, sensor fusion, SLAM, and developing heuristics and learning-based algorithms for motion planning of indoor and outdoor autonomous vehicles.\nI am an experienced industry professional and have worked in the automotive industry for three years as a Design Engineer at the R\u0026amp;D of TVS Motor Company, India, where I was responsible for powertrain design and development.\nI enjoy playing tennis, running, soccer, cooking, and traveling.\n","date":1549324800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://nykabhishek.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Hi! Welcome to my webpage.\nIâ€™m Abhishek Nayak, a Ph.D. candidate in the Department of Mechanical Engineering at Texas A\u0026amp;M University, College Station. My research interests include perception and motion planning for Robots.","tags":null,"title":"Abhishek Nayak","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://nykabhishek.github.io/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://nykabhishek.github.io/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://nykabhishek.github.io/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. --   ","date":1634304600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634304600,"objectID":"e041b596021df9443504b4b81635d526","permalink":"https://nykabhishek.github.io/talk/21_10_15_safed_webinar/","publishdate":"2021-10-15T13:30:00Z","relpermalink":"/talk/21_10_15_safed_webinar/","section":"talk","summary":"SAFE-D Webinar on Reference Machine Vision for ADAS Functions","tags":[],"title":"Webinar - Reference Machine Vision for ADAS Functions","type":"talk"},{"authors":null,"categories":null,"content":"Location: Autonomous Systems Laboratory (https://autonomy.engr.tamu.edu/), Texas A\u0026amp;M University - College Station, TX\n ROSBots by Husarion  --     ","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"75901ef2abbccdecf0cadae970d6180f","permalink":"https://nykabhishek.github.io/project/multislam/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/project/multislam/","section":"project","summary":"Implemented multi-agent SLAM to construct occupancy grid maps using ROSBots 2.0 by Husatrion. These robots were also used as a demonstration platform to showcase the motion planning algorithms I developed as part of my PhD thesis on \"Planning and Vision-based tools for Autonomous Vehicles\"","tags":["Planning","Algorithms","Heuristics"],"title":"Multi-Agent SLAM and navigation using ROSBot","type":"project"},{"authors":null,"categories":null,"content":"Location: Autonomous Systems Laboratory (https://autonomy.engr.tamu.edu/), Texas A\u0026amp;M University - College Station, TX\n   Collaborators: Satyanarayana G Manyam (https://scholar.google.com/citations?user=biUXytYAAAAJ\u0026hl=en\u0026oi=ao) ","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"cd4b134e82b7ffcc5b35d732aba70f9d","permalink":"https://nykabhishek.github.io/project/obstacle/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/project/obstacle/","section":"project","summary":"In this project, I developed new bounding approaches for shortest path problems involving curvature constrained robots in presence of obstacles.","tags":["Path Planning","Algorithms","Heuristics"],"title":"Robotic path planning algorithms in presence of obstacles","type":"project"},{"authors":["S. K. K. Hari","A. Nayak","S. Rathinam"],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"66c6af6d2c0c85cdcfd590f284bfc2c7","permalink":"https://nykabhishek.github.io/publication/8977310/","publishdate":"2020-03-22T05:35:56.031343Z","relpermalink":"/publication/8977310/","section":"publication","summary":"This article presents an approximation algorithm for a Task Allocation, Sequencing and Scheduling Problem (TASSP) involving a team of human operators and robots. The robots have to travel to a given set of targets and collaboratively work on the tasks at the targets with the human operators. The problem aims to find a sequence of targets for each robot to visit and schedule the tasks at the targets with the human operators such that each target is visited exactly once by some robot, the scheduling constraints are satisfied and the maximum mission time of any robot is minimum. This problem is a generalization of the single Traveling Salesman Problem and is NP-Hard. Given $k$ robots and $m$ human operators, an algorithm is developed for solving the TASSP with an approximation ratio equal to $\u000crac{5}{2}-\u000cracfrac{1}{k}$ when $mâ‰¥ k$ and equal to $\u000crac{7]}{2}-\u000crac{1}{k}$ otherwise. Computational results are also presented to corroborate the performance of the proposed algorithm.","tags":null,"title":"An Approximation Algorithm for a Task Allocation, Sequencing and Scheduling Problem Involving a Human-Robot Team","type":"publication"},{"authors":null,"categories":null,"content":"Location: Autonomous Systems Laboratory (https://autonomy.engr.tamu.edu/), Texas A\u0026amp;M University - College Station, TX\n Arduino microcontroller based drive-by-wire setup.      -- ","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"50d211189cd4407f4ae88cdb98361e5e","permalink":"https://nykabhishek.github.io/project/vns_dubins/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/vns_dubins/","section":"project","summary":"As a part of this work, I developed heuristics, Mixed-Integer programs (MIP), trained neural networks, and reinforcement learning (RL) models to solve curvature-constrained multi-vehicle routing problems. The reinforcement learning (RL) models and recurrent neural networks (RNNâ€™s) for graphs were implemented and trained using PyTorch. The Mixed-Integer programs (MIP) formulations were solved using CPLEX solvers on high-performance computing servers.","tags":["Path Planning","Heuristics","Algorithms"],"title":"Heuristics and Reinforcement learning models for curvature constrained vehicle routing problems","type":"project"},{"authors":["Abhishek Nayak","Sivakumar Rathinam","Adam Pike","Swaminathan Gopalswamy"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"b45cc32477596c7e16e2c79b17ed5cdd","permalink":"https://nykabhishek.github.io/publication/nayak-2020-reference/","publishdate":"2020-03-22T05:35:56.030763Z","relpermalink":"/publication/nayak-2020-reference/","section":"publication","summary":"LDW and LKA systems have the potential to prevent or mitigate 483,000 crashes in the United States every year which includes 87,000 nonfatal injury crashes and 10,345 fatal crashes. Studies have shown that fatalities due to unintentional roadway departures can be significantly reduced if Lane Departure Warning (LDW) and Lane Keep Assist (LKA) systems are used effectively. While LDW and LKA technologies are available, there has been low customer acceptance and penetration of these technologies. These deficiencies can be traced to the inability of many of the perception systems to consistently recognize lane markings and localize the vehicle with respect to the lane marking in a real-world environment of variable markings, changing weather and occlusions. These challenges translate to (i) inconsistent lane detection; (ii) misidentification of lane markings; and (iii) the inability of the systems to locate lane markings in some conditions. Currently, there is no available standard or benchmark to evaluate the quality of either the lane markings or the perception algorithms. This project seeks to establish a reference test system that could be used by transportation agencies to evaluate the quality of their markings to support ADAS functions that rely on pavement markings. The test system can also be used by system designers as a benchmark for their proprietary systems. The reference test system is comprised of a set of test scenarios, defined by roadway and environmental features, as well as pavement marking presence and luminance variables. To support the development of the system, an extensive video dataset was collected at different times of day and weather conditions on various roads in Central Texas. The videos were evaluated on different state-of-the-art lane detection algorithms and their performance was ranked based on a set of metrics specifically developed for evaluating the effectiveness of lane estimation system. A systems approach is presented by correlating the algorithm performance data to the type, marking color, marking material, and the retroreflectivity of pavement markings. Using the results obtained, a reference Lane Detection (LD) system is proposed to benchmark and rank new perception algorithms, sensors, and lane markings that constitute a reference lane system.","tags":null,"title":"Reference Test System for Machine Vision Used for ADAS Functions","type":"publication"},{"authors":[],"categories":null,"content":"   Event Flyer   ","date":1570728600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570728600,"objectID":"8747ec2f15f17b1ee0ba241f608773be","permalink":"https://nykabhishek.github.io/talk/19_10_10_safed_utc/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_10_10_safed_utc/","section":"talk","summary":"A brief on my activites as a TTI Researcher at the Safe-D UTC Graduate Student Leadership Development Seminars.","tags":[],"title":"Invited talk - Referance Machine Vision for ADAS Functions","type":"talk"},{"authors":[],"categories":null,"content":"   Poster    Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1570728600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570728600,"objectID":"610b755e8f4f97d3663d10075f93529a","permalink":"https://nykabhishek.github.io/talk/19_07_16_avs_rmv/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_07_16_avs_rmv/","section":"talk","summary":"Poster presentation at the Automated Vehicles Symposium 2019, Orlando FL","tags":[],"title":"Poster presentation - Reference Machine Vision for ADAS","type":"talk"},{"authors":["D. Ravipati","K. Chour","A. Nayak","T. Marr","S. Dey","A. Gautam","S. Rathinam","G. Swaminathan"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"044cc08fca99dc63b76ea03aeaee36e6","permalink":"https://nykabhishek.github.io/publication/8916896/","publishdate":"2020-03-22T05:35:56.032097Z","relpermalink":"/publication/8916896/","section":"publication","summary":"Infrastructure Enabled Autonomy (IEA) is a new paradigm in autonomous vehicles research that aims at distributed intelligence architecture by transferring the core functionalities of sensing and localization to infrastructure. This paradigm is also promising in designing scalable systems that enable autonomous car platooning on highways. This paper gives a detailed description about the experimental realization of IEA and techniques devised to localize a vehicle in such a setup. A reliable camera calibration technique for such an experimental setup is discussed, followed by a technique to transform 2D image coordinates to 3D world coordinates. In this research, localization information is received from on-board vehicle sensors like GPS/IMU, and (2) localized vehicle position data derived from deep learning, and 2D to 3D coordinate transformations on the real-time camera feeds and (3) lane detection data from infrastructure cameras. This data is fused together utilizing an Extended Kalman Filter (EKF) to obtain reliable estimates of the position of the vehicle at 50 Hz. This position information is then used to control the vehicle with an objective of following a prescribed path. Extensive simulation and experimental results are also presented to corroborate the performance of the proposed approach.","tags":null,"title":"Vision Based Localization for Infrastructure Enabled Autonomy","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it ðŸ™Œ ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://nykabhishek.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1556645400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556645400,"objectID":"a58c76a674386df3bc6e6239a9aba26c","permalink":"https://nykabhishek.github.io/talk/19_04_30_tti_rmv/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_04_30_tti_rmv/","section":"talk","summary":"Poster presentation at the 4th Annual Texas A\u0026M Transportation Technology Conference, College Station TX.","tags":[],"title":"Poster presentation - Reference Machine Vision for ADAS","type":"talk"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1556645400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556645400,"objectID":"72f5d24a263d97a954e572d812d9669d","permalink":"https://nykabhishek.github.io/talk/19_04_30_tti_ravev/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_04_30_tti_ravev/","section":"talk","summary":"Poster presentation at the 4th Annual Texas A\u0026M Transportation Technology Conference, College Station TX.","tags":[],"title":"Poster presentation - Response of Autonomous Vehicles to Emergency Vehicles","type":"talk"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1556038800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556038800,"objectID":"89ffe91c406020da9d794524e7bc8ace","permalink":"https://nykabhishek.github.io/talk/19_04_23_cscrs/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/19_04_23_cscrs/","section":"talk","summary":"Poster presentation at the 2019 CSCRS Safe Systems Summit, Durham NC.","tags":[],"title":"Poster presentation - Response of Autonomous Vehicles to Emergency Vehicles","type":"talk"},{"authors":["Abhishek Nayak"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://nykabhishek.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://nykabhishek.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":" Location: Texas A\u0026M Transportation Institute (TTI) - College Station, TX  Abstract: Studies have shown that fatalities due to unintentional roadway departures can be significantly reduced if Lane Departure Warning (LDW) and Lane Keep Assist (LKA) systems are used effectively. However, these systems are not yet popular because the systems are not robust due, in part to the lack of suitable standards for pavement markings that enable reliable functionality of the sensor system. The objective of this project is to develop a reference Lane Detection (LD) system that will provide a benchmark for evaluating different lane markings, sensors, and perception algorithms. The goal of the project is to create a system that will validate the effectiveness of lane markings as well as the vision algorithms through a systematic development of LD metrics, and testing procedures for LD algorithms.  Follow this link to view the project on Safe-D Website.  This is Safe-D UTC sponsored project. (https://rip.trb.org/view/1599232)  Referances: Nayak, A., Pike, A., Rathinam, S., \u0026 Gopalswamy, S. (2020). Reference test system for machine vision used for ADAS functions (No. 2020-01-0096). SAE Technical Paper.       ","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"0c279eab384537c8e85b76b0d4ae2562","permalink":"https://nykabhishek.github.io/project/rmv/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/project/rmv/","section":"project","summary":"The objective of this project was to develop a reference Lane Detection (LD) system that will provide a benchmark for evaluating different lane markings, sensors, and perception algorithms. An extensive video dataset was developed by driving on various roads in Central Texas with changing weather conditions, time of day, pavement marking presence, and luminance variables. The dataset was used to develop a reference system to benchmark lane marking materials and their effect on lane detection (LD) performance of perception algorithms used in Lane Departure Warning (LDW) and Lane Keep Assist (LKA) modules.","tags":["Deep Learning","Computer Vision"],"title":"Reference Machine Vision for ADAS functions","type":"project"},{"authors":["Abhishek Nayak","Swaminathan Gopalswamy","Sivakumar Rathinam"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d7a7731693b1f78e21b6610202cdb0ce","permalink":"https://nykabhishek.github.io/publication/nayak-2019-vision/","publishdate":"2020-03-22T05:35:56.03307Z","relpermalink":"/publication/nayak-2019-vision/","section":"publication","summary":"This paper discusses different computer vision techniques investigated by the authors for identifying Emergency Vehicles (EV). Two independent EV identification frameworks were investigated: (1) A one-stage framework where an object detection algorithm is trained on a custom dataset to detect EVs, (2) A two-stage framework where an object classification algorithm is implemented in series with an object detection pipeline to classify vehicles into EVs and non-EVs. A comparative study is conducted for different multi-spectral feature vectors of the image, against several classification models implemented in framework 2. Additionally, a user-defined feature vector is defined and its performance is compared against the other feature vectors. Classification outputs from each of the frameworks are compared to the ground truth, and results are quantitatively listed to conclude upon the ideal decision rule. As maintaining the speed of data output is the priority throughout our development, a computationally inexpensive object tracking algorithm is selected to accurately track EV between image frames. This vision-based EV detection scheme fused with data from other sensors on our autonomous vehicle shall be used to establish a sensor-fusion based EV detection and response framework in future work.","tags":null,"title":"Vision-Based Techniques for Identifying Emergency Vehicles","type":"publication"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/). Further talk details can easily be added to this page using *Markdown* and $\\rm \\LaTeX$ math code. -- ","date":1525800600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525800600,"objectID":"913ccfbb8aa51051098ffdebd7c73e8d","permalink":"https://nykabhishek.github.io/talk/18_05_18_tti_ravev/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/18_05_18_tti_ravev/","section":"talk","summary":"Poster presentation at the 3rd Annual Texas A\u0026M Transportation Technology Conference, College Station TX.","tags":[],"title":"Poster presentation - Response of Autonomous Vehicles to Emergency Vehicles","type":"talk"},{"authors":null,"categories":null,"content":"Location: Texas A\u0026M Transportation Institute (TTI) - College Station, TX --  Abstract: The objective of this project is to explore an ideal response action of an autonomous vehicle towards response vehicles in emergency scenarios using vision, sound and other sensors. I developed vision-based algorithms to reliably detect and track emergency vehicles from a video feed using image processing, machine learning, deep neural networks and other computer vison techniques.  Visit Project Website  This was a Safe-D UTC sponsored project (https://rip.trb.org/view/1500797).  Follow this link to view the project on Safe-D Website.  The final report of the project can be viewed here.  References:  Nayak, A., Gopalswamy, S., \u0026 Rathinam, S. (2019). Vision-Based Techniques for Identifying Emergency Vehicles (No. 2019-01-0889). SAE Technical Paper. Nayak, A., Rathinam, S., \u0026 Gopalswamy, S. (2020). Response of Autonomous Vehicles to Emergency Response Vehicles (RAVEV) (No. 03-051).   Videos:    Emergency Vehicle (EV) detection: This video shows the emergency vehicles being detected by the trained YOLO-v3 object detector.    RAVEV - Hidden line of sight: This video shows the response by an autonomous vehicle when being followed by an EV with an obscured line of sight. This video was collected at RELLIS campus facility of Texas A\u0026M University.     RAVEV - Clear line of sight: This video shows the response by an autonomous vehicle when being followed by an EV with a clear line of sight. This video was collected at RELLIS campus facility of Texas A\u0026M University.     High-speed lane change: This video shows in action the high speed vehicle controller developed as a part of the RAVEV project. This video was collected at RELLIS campus facility of Texas A\u0026M University.  ","date":1517011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517011200,"objectID":"8d7ffc4e72bf2066f3908f9c6ef1e952","permalink":"https://nykabhishek.github.io/project/ravev/","publishdate":"2018-01-27T00:00:00Z","relpermalink":"/project/ravev/","section":"project","summary":"The objective of this project was to develop response protocols for an autonomous vehicle when it senses the presence of emergency vehicles using sound, vision, and other onboard sensors. As part of the project, I developed a public image dataset for Emergency vehicles (EV); trained object detection, classification, and tracking models developed using scikit-learn and Keras, and implemented SLAM for control of the autonomous vehicle in the presence of emergency responders.","tags":["Autonomous Vehicles","Computer Vision","Machine Learning","Deep Learning","Sensor Fusion"],"title":"Response of Autonomous Vehicles to Emergency Response Vehicles (RAVEV)","type":"project"},{"authors":["Abhishek Nayak","Kenny Chour","Tyler Marr","Deepika Ravipati","Sheelabhadra Dey","Alvika Gautam","Swaminathan Gopalswamy","Sivakumar Rathinam"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"9ad05b55efcac26f5c96ea0d14922bd4","permalink":"https://nykabhishek.github.io/publication/nayak-2018-distributed/","publishdate":"2020-03-22T05:35:56.029689Z","relpermalink":"/publication/nayak-2018-distributed/","section":"publication","summary":"Infrastructure Enabled Autonomy (IEA) is a new paradigm that employs a distributed intelligence architecture for connected autonomous vehicles by offloading core functionalities to the infrastructure. In this paper, we develop a simulation framework that can be used to study the concept. A key challenge for such a simulation is the rapid increase in the scale of the computations with the size of the infrastructure to be considered. Our simulation framework is designed to be distributed and scales proportionally with the infrastructure. By integrally using both the hardware controllers and communication devices as part of the simulation framework, we achieve an optimal balance between modeling of the dynamics and sensors, and reusing real hardware for simulation of proprietary or complex communication methods. Multiple cameras on the infrastructure are simulated. The simulation of the camera image processing is done in distributed hardware and the resultant position information is transmitted wirelessly to the computer simulating the autonomous vehicle. We demonstrate closed loop control of a single vehicle following given waypoints using information from multiple cameras located on Road-Side-Units.","tags":null,"title":"A Distributed Hybrid Hardware-in-the-loop Simulation Framework for Infrastructure Enabled Autonomy","type":"publication"},{"authors":null,"categories":null,"content":" Location: CAST Program, Texas A\u0026M University - College Station, TX Abstract: IEA is a new paradigm in Autonomous Vehicle technology that looks at offloading the core computational capabilities of awareness generation and path planning from the vehicle out onto Smart Roadside Units equipped with various sensors. Through this distributed setup IEA provides a solution of shared liabilities by transferring the primary responsibility of localization from vehicle to infrastructure which in-turn enables of greater situational awareness of the area under the purview of IEA. IEA architecture is deployed on specific sections of roads or special traffic corridors by installing Road-Side Units (RSU) on either side of the road. These RSUs are fitted with multi-sensor smart packs (MSSP) containing sensors required for localizing vehicles. These MSSPs monitor the vehicles in the section of the roads under the purview of IEA and aid in generating the situational awareness which can be transmitted to the vehicles subscribing to this information. MSSP includes several sensors that carry-out specific individual tasks and as a whole aid in generating the localization information. For example, cameras installed on the RSUs as a part of the MSSP are used to monitor traffic by identifying and locating all the objects of interest in the traffic corridor. MSSPs are installed with special SmartConnect devices, whose function is to establish wireless connectivity between MSSPs and the vehicles subscribing to its information and thus enabling transmission of information necessary for its localization. The SmartConnect devices are communication medium agnostic and modular so that they can be easily substituted by newer technologies.  Referances: Nayak, A., Chour, K., Marr, T., Ravipati, D., Dey, S., Gautam, A., ... \u0026 Rathinam, S. (2018). A distributed hybrid hardware-in-the-loop simulation framework for infrastructure enabled autonomy. arXiv preprint arXiv:1802.01787. Ravipati, D., Chour, K., Nayak, A., Marr, T., Dey, S., Gautam, A., ... \u0026 Swaminathan, G. (2019, October). Vision Based Localization for Infrastructure Enabled Autonomy. In 2019 IEEE Intelligent Transportation Systems Conference (ITSC) (pp. 1638-1643). IEEE. Gopalswamy, S., \u0026 Rathinam, S. (2018, June). Infrastructure enabled autonomy: A distributed intelligence architecture for autonomous vehicles. In 2018 IEEE Intelligent Vehicles Symposium (IV) (pp. 986-992). IEEE.            ","date":1503792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503792000,"objectID":"de6fb5f0a909f7f6b2f76f2caae52db3","permalink":"https://nykabhishek.github.io/project/iea/","publishdate":"2017-08-27T00:00:00Z","relpermalink":"/project/iea/","section":"project","summary":"The objective of this project was to develop a distributed intelligence architecture for connected autonomous vehicles by offloading core computational functionalities to the infrastructure. I worked on establishing the V2V and V2I communication network using DSRC; developed machine vision capabilities like object detection, semantic segmentation, and tracking for smart-infrastructure-assisted SLAM and autonomous control for connected vehicles.","tags":["Autonomous Vehicles","Computer Vision","Deep Learning","Sensor Fusion"],"title":"Infrastructure Enabled Autonomy (IEA)","type":"project"},{"authors":null,"categories":null,"content":"Location: CAST Program (https://cast.tamu.edu/), Texas A\u0026amp;M University - College Station, TX\n  Arduino microcontroller based drive-by-wire setup.       Collaborators: Kenny Chour, PhD Student - Texas A\u0026M University ","date":1503360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503360000,"objectID":"f756b65fe8b4cad2715c77f4d1d5b680","permalink":"https://nykabhishek.github.io/project/focus/","publishdate":"2017-08-22T00:00:00Z","relpermalink":"/project/focus/","section":"project","summary":"Implementation of low-cost drive-by-wire control capability via sensor emulation using Arduino Mega on a Ford focus vehicle.","tags":["Autonomous Vehicles","Sensor Fusion"],"title":"Development of autonomous driving capability on a Ford Focus","type":"project"},{"authors":["Abhishek Nayak"],"categories":["Demo"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\n Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n ðŸ‘‰ Get Started ðŸ“š View the documentation ðŸ’¬ Ask a question on the forum ðŸ‘¥ Chat with the community ðŸ¦ Twitter: @source_themes @GeorgeCushen #MadeWithAcademic ðŸ’¡ Request a feature or report a bug â¬†ï¸ Updating? View the Update Guide and Release Notes â¤ Support development of Academic:  â˜•ï¸ Donate a coffee ðŸ’µ Become a backer on Patreon ðŸ–¼ï¸ Decorate your laptop or journal with an Academic sticker ðŸ‘• Wear the T-shirt ðŸ‘©â€ðŸ’» Contribute      Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, ä¸­æ–‡, and PortuguÃªs Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\n Choose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem   Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site  Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n  one-click install using your web browser (recommended)  install on your computer using Git with the Command Prompt/Terminal app  install on your computer by downloading the ZIP files  install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating  View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://nykabhishek.github.io/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Abhishek Nayak","HS Ashwin","SM Murigendrappa"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"93b1f7b81488004101dc0c99b2559d67","permalink":"https://nykabhishek.github.io/publication/nayak-2016-stability/","publishdate":"2020-03-22T05:35:56.033939Z","relpermalink":"/publication/nayak-2016-stability/","section":"publication","summary":"During cornering of a two wheeler under dynamic conditions when the vehicle is steered to the left or right, the axis of the wheels and other rotating parts undergoes precession along with spinning which produces a gyroscopic couple. Due to the action of these moments on the vehicles along with the centrifugal forces and gravity acting on it, the vehicle may either skid or overturn depending on the angle of tilt, velocity of the motorcycle, radius of the curve \u0026 mass of the vehicle. The main objective of this work is to ensure the safe negotiation of the turn and to prevent accidents by establishing a harmonious relationship between the effecting parameters. A device was developed to act as a feedback control system; taking the inputs from a IMU sensor, predict the equilibrium conditions and thereby control the dynamic parameters of the 2 wheeler in order to enable it negotiate the curve safely.","tags":null,"title":"Stability Enhancement Of a Powered Two Wheeler Vehicle Under Curve Negotiation","type":"publication"}]