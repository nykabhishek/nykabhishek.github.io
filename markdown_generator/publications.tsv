pub_date	title	venue	excerpt	citation	url_slug	paper_url
4/14/2020	Reference test system for machine vision used for ADAS functions	SAE Technical Paper	"LDW and LKA systems have the potential to prevent or mitigate 483,000 crashes in the United States every year which includes 87,000 nonfatal injury crashes and 10,345 fatal crashes. Studies have shown that fatalities due to unintentional roadway departures can be significantly reduced if Lane Departure Warning (LDW) and Lane Keep Assist (LKA) systems are used effectively. While LDW and LKA technologies are available, there has been low customer acceptance and penetration of these technologies. These deficiencies can be traced to the inability of many of the perception systems to consistently recognize lane markings and localize the vehicle with respect to the lane marking in a real-world environment of variable markings, changing weather and occlusions. These challenges translate to (i) inconsistent lane detection; (ii) misidentification of lane markings; and (iii) the inability of the systems to locate lane markings in some conditions. Currently, there is no available standard or benchmark to evaluate the quality of either the lane markings or the perception algorithms. This project seeks to establish a reference test system that could be used by transportation agencies to evaluate the quality of their markings to support ADAS functions that rely on pavement markings. The test system can also be used by system designers as a benchmark for their proprietary systems. The reference test system is comprised of a set of test scenarios, defined by roadway and environmental features, as well as pavement marking presence and luminance variables. To support the development of the system, an extensive video dataset was collected at different times of day and weather conditions on various roads in Central Texas. The videos were evaluated on different state-of-the-art lane detection algorithms and their performance was ranked based on a set of metrics specifically developed for evaluating the effectiveness of lane estimation system. A systems approach is presented by correlating the algorithm performance data to the type, marking color, marking material, and the retroreflectivity of pavement markings. Using the results obtained, a reference Lane Detection (LD) system is proposed to benchmark and rank new perception algorithms, sensors, and lane markings that constitute a reference lane system."	"Nayak, A., Pike, A., Rathinam, S., & Gopalswamy, S. (2020). Reference test system for machine vision used for ADAS functions (No. 2020-01-0096). SAE Technical Paper."	paper-title-number-1	https://www.sae.org/publications/technical-papers/content/2020-01-0096/
1/31/2020	"An Approximation Algorithm for a Task Allocation, Sequencing and Scheduling Problem involving a Human-Robot Team"	arXiv preprint 	"This article presents an approximation algorithm for a task allocation, sequencing and scheduling problem involving a team of human operators and robots. Specifically, we present an algorithm with an approximation ratio as a function of the number of human operators ($ m $) and the number of robots ($ k $) in the team. The approximation ratios are $\frac {7}{2}-\frac {5}{4k} $, $\frac {5}{2}-\frac {1}{k} $ and $\frac {7}{2}-\frac {1}{k} $ when $ m= 1$, $ m\geq k\geq 2$ and $ k> m\geq 2$ respectively."	"Hari, Sai Krishna, Abhishek Nayak, and Sivakumar Rathinam. ""An Approximation Algorithm for a Task Allocation, Sequencing and Scheduling Problem involving a Human-Robot Team."" arXiv preprint arXiv:1907.01692 (2019)."	paper-title-number-2	https://ieeexplore.ieee.org/document/8977310
11/28/2019	Vision Based Localization for Infrastructure Enabled Autonomy	"2019 IEEE Intelligent Transportation Systems Conference (ITSC), Auckland, New Zealand"	"Infrastructure Enabled Autonomy (IEA) is a new paradigm in autonomous vehicles research that aims at distributed intelligence architecture by transferring the core functionalities of sensing and localization to infrastructure. This paradigm is also promising in designing scalable systems that enable autonomous car platooning on highways. This paper gives a detailed description about the experimental realization of IEA and techniques devised to localize a vehicle in such a setup. A reliable camera calibration technique for such an experimental setup is discussed, followed by a technique to transform 2D image coordinates to 3D world coordinates. In this research, localization information is received from on-board vehicle sensors like GPS/IMU, and (2) localized vehicle position data derived from deep learning, and 2D to 3D coordinate transformations on the real-time camera feeds and (3) lane detection data from infrastructure cameras. This data is fused together utilizing an Extended Kalman Filter (EKF) to obtain reliable estimates of the position of the vehicle at 50 Hz. This position information is then used to control the vehicle with an objective of following a prescribed path. Extensive simulation and experimental results are also presented to corroborate the performance of the proposed approach."	"Deepika Ravipati, Kenny Chour, Abhishek Nayak, Tyler Marr, Sheelabhadra Dey, Alvika Gautam, Sivakumar Rathinam, Swaminathan Gopalswamy, ""Vision Based Localization for Infrastructure Enabled Autonomy,"" 2019 IEEE Intelligent Transportation Systems Conference (ITSC), Auckland, New Zealand, 2019, pp. 1638-1643. doi: 10.1109/ITSC.2019.8916896"	paper-title-number-3	https://ieeexplore.ieee.org/document/8916896
4/2/2019	Vision-Based Techniques for Identifying Emergency Vehicles	SAE Technical Paper	"This paper discusses different computer vision techniques investigated by the authors for identifying Emergency Vehicles (EV). Two independent EV identification frameworks were investigated: (1) A one-stage framework where an object detection algorithm is trained on a custom dataset to detect EVs, (2) A two-stage framework where an object classification algorithm is implemented in series with an object detection pipeline to classify vehicles into EVs and non-EVs. A comparative study is conducted for different multi-spectral feature vectors of the image, against several classification models implemented in framework 2. Additionally, a user-defined feature vector is defined and its performance is compared against the other feature vectors. Classification outputs from each of the frameworks are compared to the ground truth, and results are quantitatively listed to conclude upon the ideal decision rule. As maintaining the speed of data output is the priority throughout our development, a computationally inexpensive object tracking algorithm is selected to accurately track EV between image frames. This vision-based EV detection scheme fused with data from other sensors on our autonomous vehicle shall be used to establish a sensor-fusion based EV detection and response framework in future work."	"Nayak, A., Gopalswamy, S., and Rathinam, S., ""Vision-Based Techniques for Identifying Emergency Vehicles,"" SAE Technical Paper 2019-01-0889, 2019, https://doi.org/10.4271/2019-01-0889."	paper-title-number-4	https://www.sae.org/publications/technical-papers/content/2019-01-0889/
2/6/2018	A Distributed Hybrid Hardware-In-the-Loop Simulation framework for Infrastructure Enabled Autonomy	arXiv preprint	"Infrastructure Enabled Autonomy (IEA) is a new paradigm that employs a distributed intelligence architecture for connected autonomous vehicles by offloading core functionalities to the infrastructure. In this paper, we develop a simulation framework that can be used to study the concept. A key challenge for such a simulation is the rapid increase in the scale of the computations with the size of the infrastructure to be considered. Our simulation framework is designed to be distributed and scales proportionally with the infrastructure. By integrally using both the hardware controllers and communication devices as part of the simulation framework, we achieve an optimal balance between modeling of the dynamics and sensors, and reusing real hardware for simulation of proprietary or complex communication methods. Multiple cameras on the infrastructure are simulated. The simulation of the camera image processing is done in distributed hardware and the resultant position information is transmitted wirelessly to the computer simulating the autonomous vehicle. We demonstrate closed loop control of a single vehicle following given waypoints using information from multiple cameras located on Road-Side-Units."	"Nayak, A., Chour, K., Marr, T., Ravipati, D., Dey, S., Gautam, A., Gopalswamy, S. and Rathinam, S., 2018. A Distributed Hybrid Hardware-In-the-Loop Simulation framework for Infrastructure Enabled Autonomy. arXiv preprint arXiv:1802.01787."	paper-title-number-5	https://arxiv.org/abs/1802.01787
